{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b657acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from openai import AzureOpenAI\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3832c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "AZURE_SEARCH_SERVICE=os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_KEY=os.getenv(\"AZURE_SEARCH_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_VERSION=os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    "AZURE_OPENAI_KEY=os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_DEPLOYMENT=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "AZURE_STORAGE_CONNECTION=os.getenv(\"AZURE_STORAGE_CONNECTION\")\n",
    "AZURE_OPENAI_EMBEDDING_MODEL=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "AZURE_AI_MULTISERVICE_KEY=os.getenv(\"AZURE_AI_MULTISERVICE_KEY\")\n",
    "\n",
    "credential = AzureKeyCredential(AZURE_SEARCH_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32503c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = AzureOpenAI(\n",
    "  api_key = AZURE_OPENAI_KEY,  \n",
    "  api_version = AZURE_OPENAI_VERSION,\n",
    "  azure_endpoint =AZURE_OPENAI_ENDPOINT,\n",
    "  azure_deployment=AZURE_OPENAI_DEPLOYMENT,\n",
    ")\n",
    "\n",
    "index_name = \"py-rag-tutorial-idx\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "     endpoint=AZURE_SEARCH_SERVICE,\n",
    "     index_name=index_name,\n",
    "     credential=credential\n",
    " )\n",
    "\n",
    "# Prompt is unchanged in this update\n",
    "GROUNDED_PROMPT=\"\"\"\n",
    "You are an AI assistant that helps users learn from the information found in the source material.\n",
    "Answer the query using only the sources provided below.\n",
    "Use bullets if the answer has multiple points.\n",
    "If the answer is longer than 3 sentences, provide a summary.\n",
    "Answer ONLY with the facts listed in the list of sources below. Cite your source when you answer the question\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the sources below.\n",
    "Query: {query}\n",
    "Sources:\\n{sources}\n",
    "\"\"\"\n",
    "\n",
    "# Queries are unchanged in this update\n",
    "query=\"Are there any cloud formations specific to oceans and large bodies of water?\"\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\"text_vector\")\n",
    "\n",
    "# Add query_type semantic and semantic_configuration_name\n",
    "# Add scoring_profile and scoring_parameters\n",
    "search_results = search_client.search(\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"my-semantic-config\",\n",
    "    scoring_profile=\"my-scoring-profile\",\n",
    "    scoring_parameters=[\"tags-ocean, 'sea surface', seas, surface\"],\n",
    "    search_text=query,\n",
    "    vector_queries= [vector_query],\n",
    "    select=\"title, chunk, locations\",\n",
    "    top=5,\n",
    ")\n",
    "sources_formatted = \"=================\\n\".join([f'TITLE: {document[\"title\"]}, CONTENT: {document[\"chunk\"]}, LOCATIONS: {document[\"locations\"]}' for document in search_results])\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": GROUNDED_PROMPT.format(query=query, sources=sources_formatted)\n",
    "        }\n",
    "    ],\n",
    "    model=AZURE_OPENAI_DEPLOYMENT,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
